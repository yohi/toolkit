#!/usr/bin/env python3
"""
GitHub PR #104 ã‚³ãƒ¡ãƒ³ãƒˆå‡¦ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‘ã‘ã«æ§‹é€ åŒ–ã•ã‚ŒãŸã‚³ãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
"""

import json
import os
from datetime import datetime, timezone
from pathlib import Path


def process_pr_comments():
    """ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’å‡¦ç†ã—ã¦AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‘ã‘å½¢å¼ã§å‡ºåŠ›"""

    # ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«åŸºæº–ã®ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¨­å®š
    base_dir = Path(__file__).resolve().parent

    # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    try:
        pr_data_path = base_dir / "pr_104_raw_data.json"
        with open(pr_data_path, "r", encoding="utf-8") as f:
            pr_data = json.load(f)
    except FileNotFoundError as e:
        print(f"âŒ PR data file not found at {pr_data_path}: {e}")
        return
    except json.JSONDecodeError as e:
        print(f"âŒ Invalid JSON in PR data file {pr_data_path}: {e}")
        return
    except OSError as e:
        print(f"âŒ I/O error reading PR data file {pr_data_path}: {e}")
        return

    try:
        inline_comments_path = base_dir / "pr_104_inline_comments.json"
        with open(inline_comments_path, "r", encoding="utf-8") as f:
            inline_comments = json.load(f)
    except FileNotFoundError as e:
        print(f"âŒ Inline comments file not found at {inline_comments_path}: {e}")
        inline_comments = []
    except json.JSONDecodeError as e:
        print(f"âŒ Invalid JSON in inline comments file {inline_comments_path}: {e}")
        inline_comments = []
    except OSError as e:
        print(f"âŒ I/O error reading inline comments file {inline_comments_path}: {e}")
        inline_comments = []

    try:
        reviews_path = base_dir / "pr_104_reviews.json"
        with open(reviews_path, "r", encoding="utf-8") as f:
            reviews = json.load(f)
    except FileNotFoundError as e:
        print(f"âŒ Reviews file not found at {reviews_path}: {e}")
        reviews = []
    except json.JSONDecodeError as e:
        print(f"âŒ Invalid JSON in reviews file {reviews_path}: {e}")
        reviews = []
    except OSError as e:
        print(f"âŒ I/O error reading reviews file {reviews_path}: {e}")
        reviews = []

    # AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‘ã‘ã®æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
    structured_data = {
        "metadata": {
            "pull_request_number": pr_data.get("number"),
            "title": pr_data.get("title"),
            "extraction_timestamp": datetime.now(timezone.utc).isoformat(),
            "total_inline_comments": len(inline_comments),
            "total_reviews": len(reviews),
            "data_sources": ["pr_data", "inline_comments", "reviews"],
            "processing_script": "process_pr_comments.py",
        },
        "pull_request_info": {
            "number": pr_data.get("number"),
            "title": pr_data.get("title"),
            "body": (lambda body: body[:500] + ("..." if len(body) > 500 else ""))(
                pr_data.get("body") or ""
            ),
        },
        "inline_comments": [],
        "review_comments": [],
        "actionable_items": [],
        "coderabbit_analysis": {
            "total_coderabbit_comments": 0,
            "actionable_count": 0,
            "file_coverage": [],
        },
    }

    # ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ã‚³ãƒ¡ãƒ³ãƒˆã‚’å‡¦ç†
    coderabbit_count = 0
    files_mentioned = set()

    for comment in inline_comments:
        # Safe extraction of user login with None protection
        user_data = comment.get("user") or {}
        user_login = user_data.get("login") or ""

        # Safe extraction of body with None protection
        body_text = comment.get("body") or ""

        is_coderabbit = "coderabbit" in user_login.lower()

        if is_coderabbit:
            coderabbit_count += 1

        file_path = comment.get("path")
        if file_path:
            files_mentioned.add(file_path)

        structured_comment = {
            "id": comment.get("id"),
            "user": user_login,
            "created_at": comment.get("created_at"),
            "updated_at": comment.get("updated_at"),
            "body": body_text,
            "path": file_path,
            "line": comment.get("line"),
            "start_line": comment.get("start_line"),
            "side": comment.get("side"),
            "position": comment.get("position"),
            "commit_id": comment.get("commit_id"),
            "in_reply_to_id": comment.get("in_reply_to_id"),
            "is_coderabbit": is_coderabbit,
            "body_length": len(body_text),
            "has_suggestions": "```suggestion" in body_text.lower(),
        }
        structured_data["inline_comments"].append(structured_comment)

    # ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚³ãƒ¡ãƒ³ãƒˆã‚’å‡¦ç†
    for review in reviews:
        # Safe extraction with None protection
        user_data = review.get("user") or {}
        user_login = user_data.get("login") or ""
        body = review.get("body") or ""

        is_coderabbit = "coderabbit" in user_login.lower()

        structured_review = {
            "id": review.get("id"),
            "user": user_login,
            "state": review.get("state"),
            "body": body,
            "submitted_at": review.get("submitted_at"),
            "commit_id": review.get("commit_id"),
            "is_coderabbit": is_coderabbit,
            "body_length": len(body),
        }
        structured_data["review_comments"].append(structured_review)

    # ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚³ãƒ¡ãƒ³ãƒˆç”±æ¥ã®CodeRabbitä»¶æ•°ã‚‚åŠ ç®—
    coderabbit_count += sum(
        1 for r in reviews if "coderabbit" in (r.get("user", {}).get("login") or "").lower()
    )

    # ã‚¢ã‚¯ã‚·ãƒ§ãƒŠãƒ–ãƒ«ã‚¢ã‚¤ãƒ†ãƒ ã‚’æŠ½å‡ºï¼ˆCodeRabbitã‚³ãƒ¡ãƒ³ãƒˆä¸­å¿ƒï¼‰
    actionable_count = 0
    actionable_keywords = [
        "âš ï¸ Potential issue",
        "ğŸ› ï¸ Refactor suggestion",
        "ğŸ“ Committable suggestion",
        "ğŸ¤– Prompt for AI Agents",
        "Consider",
        "Suggestion:",
        "Issue:",
        "Problem:",
        "Warning:",
        "Error:",
    ]

    for comment in inline_comments:
        # Safe extraction with None protection
        user_data = comment.get("user") or {}
        user_login = user_data.get("login") or ""
        body = comment.get("body") or ""

        if "coderabbit" in user_login.lower():
            for keyword in actionable_keywords:
                if keyword.lower() in body.lower():
                    actionable_count += 1
                    structured_data["actionable_items"].append(
                        {
                            "comment_id": comment.get("id"),
                            "type": keyword,
                            "file": comment.get("path"),
                            "line": comment.get("line"),
                            "user": user_login,
                            "created_at": comment.get("created_at"),
                            "content_preview": body[:200] + ("..." if len(body) > 200 else ""),
                            "full_content": body,
                            "priority": (
                                "high"
                                if keyword in ["âš ï¸ Potential issue", "Error:", "Warning:"]
                                else "medium"
                            ),
                        }
                    )
                    break

    # CodeRabbitåˆ†æã‚µãƒãƒªãƒ¼ã‚’æ›´æ–°
    structured_data["coderabbit_analysis"]["total_coderabbit_comments"] = coderabbit_count
    structured_data["coderabbit_analysis"]["actionable_count"] = actionable_count
    structured_data["coderabbit_analysis"]["file_coverage"] = list(files_mentioned)

    # ãƒ•ã‚¡ã‚¤ãƒ«ã«å‡ºåŠ›
    output_file = base_dir / "pr_104_ai_friendly_comments.json"

    # Create parent directory first
    try:
        output_file.parent.mkdir(parents=True, exist_ok=True)
    except OSError as e:
        print(f"âŒ Failed to create output directory {output_file.parent}: {e}")
        return

    # Write JSON output with specific error handling
    try:
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(structured_data, f, ensure_ascii=False, indent=2)
        print(f"âœ… AI-friendly output generated: {output_file}")
    except TypeError as e:
        print(f"âŒ JSON encoding error for {output_file}: {e}")
        return
    except OSError as e:
        print(f"âŒ I/O error writing JSON file {output_file}: {e}")
        return

    # Print summary (no file I/O, should not fail)
    print("ğŸ“Š Summary:")
    print(f"  - Total inline comments: {len(inline_comments)}")
    print(f"  - Total reviews: {len(reviews)}")
    print(f"  - CodeRabbit comments: {coderabbit_count}")
    print(f"  - Actionable items found: {actionable_count}")
    print(f"  - Files with comments: {len(files_mentioned)}")

    # Write markdown report with specific error handling
    report_file = base_dir / "pr_104_analysis_report.md"
    try:
        with open(report_file, "w", encoding="utf-8") as f:
            f.write(
                f"""# PR #104 ã‚³ãƒ¡ãƒ³ãƒˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆ

## åŸºæœ¬æƒ…å ±
- **PRç•ªå·**: {pr_data.get('number')}
- **ã‚¿ã‚¤ãƒˆãƒ«**: {pr_data.get('title')}
- **å‡¦ç†æ—¥æ™‚**: {datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S %Z')}

## ã‚³ãƒ¡ãƒ³ãƒˆçµ±è¨ˆ
- **ç·ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ã‚³ãƒ¡ãƒ³ãƒˆæ•°**: {len(inline_comments)}ä»¶
- **ç·ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°**: {len(reviews)}ä»¶
- **CodeRabbitã‚³ãƒ¡ãƒ³ãƒˆæ•°**: {coderabbit_count}ä»¶
- **ã‚¢ã‚¯ã‚·ãƒ§ãƒŠãƒ–ãƒ«ã‚¢ã‚¤ãƒ†ãƒ æ•°**: {actionable_count}ä»¶
- **è¨€åŠãƒ•ã‚¡ã‚¤ãƒ«æ•°**: {len(files_mentioned)}ä»¶

## ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥ã‚³ãƒ¡ãƒ³ãƒˆåˆ†å¸ƒ
"""
            )
            for file_path in sorted(files_mentioned):
                file_comment_count = sum(1 for c in inline_comments if c.get("path") == file_path)
                f.write(f"- `{file_path}`: {file_comment_count}ä»¶\n")

            f.write(
                f"""
## ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«
- **æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿**: `{output_file.name}`
- **å…ƒãƒ‡ãƒ¼ã‚¿**: `pr_104_raw_data.json`, `pr_104_inline_comments.json`, `pr_104_reviews.json`

## AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‘ã‘æƒ…å ±
ã“ã®ãƒ‡ãƒ¼ã‚¿ã¯AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒä»¥ä¸‹ã®ç”¨é€”ã§æ´»ç”¨ã§ãã¾ã™ï¼š
1. CodeRabbitã‚³ãƒ¡ãƒ³ãƒˆã®è‡ªå‹•åˆ†æ
2. ã‚¢ã‚¯ã‚·ãƒ§ãƒŠãƒ–ãƒ«ã‚¢ã‚¤ãƒ†ãƒ ã®å„ªå…ˆåº¦ä»˜ã‘
3. ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼å¯†åº¦åˆ†æ
4. ä¿®æ­£ææ¡ˆã®è‡ªå‹•ç”Ÿæˆ
"""
            )
        print(f"ğŸ“„ Analysis report generated: {report_file}")
    except OSError as e:
        print(f"âŒ I/O error writing report file {report_file}: {e}")


if __name__ == "__main__":
    process_pr_comments()
