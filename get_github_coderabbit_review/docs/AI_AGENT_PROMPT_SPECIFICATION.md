# AI Agent Instruction Prompt Specification

## 1. Overview

This document specifies the structure and content of the AI Agent Instruction Prompt generated by the CodeRabbit Comment Fetcher. The prompt is designed to be fully compliant with [Claude 4's best practices](https://docs.claude.com/en/docs/build-with-claude/prompt-engineering/overview.md) for clarity, structure, and effectiveness.

The entire prompt is generated **mechanically** from the data fetched via the GitHub CLI. **No LLM is used in the prompt generation process itself.** The process is a deterministic, rule-based transformation of raw PR data into a structured format that an AI agent can easily parse and act upon.

## 2. Core Design Principles

- **Deterministic Generation**: The prompt is generated through a purely mechanical process (e.g., string manipulation, regex) without any LLM-based analysis or summarization. This ensures that the same input from the GitHub API always produces the exact same output.
- **Structured for Clarity**: The prompt uses a combination of Markdown and XML-style tags to clearly delineate different sections and types of information, making it easy for an AI agent to parse.
- **Role-Based Persona**: A static `<role>` tag is included at the beginning to provide the AI agent with a consistent persona as a senior software engineer, guiding its analysis and response style.
- **Action-Oriented**: The prompt's primary goal is to present raw, actionable feedback from CodeRabbit in a structured manner, enabling the AI agent to focus on analysis and solution generation.

## 3. Prompt Structure

The generated prompt consists of the following sections in order:

### 3.1. Static Header

This section provides the AI agent with its persona and a general methodology for analysis. The content is static and included in every generated prompt.

- **`<role>`**: Defines the persona for the AI agent (e.g., senior software engineer).
- **`<core_principles>`**: Lists the guiding principles for the agent's work (e.g., prioritize quality, security).
- **`<analysis_methodology>`**: Outlines a step-by-step approach for analyzing the provided comments.

### 3.2. Dynamic Context

This section provides the specific context of the pull request being analyzed. All information is dynamically populated from the GitHub CLI output.

- **`## Pull Request Context`**: Contains metadata about the PR, such as URL, title, author, and file change statistics.
- **`## CodeRabbit Review Summary`**: Provides a high-level, mechanically-counted summary of the different types of comments found (e.g., Actionable, Nitpick).

### 3.3. Analysis Task Definition

This section instructs the AI agent on what to do with the provided data and what the expected output format is.

- **`# Analysis Task`**: A clear instruction to analyze the comments within the `<review_comments>` block.
- **`<output_requirements>`**: A static template defining the exact Markdown structure the AI agent should use for its response for each analyzed comment.

### 3.4. Structured Comments Block

This is the core of the prompt, containing the structured data of the CodeRabbit comments.

- **`<review_comments>`**: The root tag containing all individual review comments.
- **`<review_comment>`**: A container for a single piece of feedback from CodeRabbit.
  - **`type` attribute**: The category of the comment, mechanically determined (e.g., `Actionable`, `Nitpick`, `OutsideDiff`).
  - **`file` attribute**: The file path the comment pertains to.
  - **`lines` attribute**: The line number or range the comment pertains to.

  - **`<issue>` tag**: Contains the title or main point of the CodeRabbit comment.
  - **`<instructions>` tag**: Contains the detailed body of the CodeRabbit comment, including any instructions or explanations. For comments that originally included a "ðŸ¤– Prompt for AI Agents", that text is placed here.
  - **`<proposed_diff>` tag**: (Optional) Contains the code diff suggested by CodeRabbit, enclosed in a `CDATA` block to ensure proper parsing.

### 3.5. Static Footer

- **`# Analysis Instructions`**: A static section that may contain a concluding message or a final thinking framework to guide the agent.

## 4. Generation Process

The prompt is generated by the `coderabbit-fetcher` tool, which:
1. Fetches PR data (metadata and review comments) using `gh pr view --json ...`.
2. Parses the raw JSON response.
3. Iterates through the review comments, extracting the title, body, file path, line numbers, and suggested diff for each piece of feedback.
4. Categorizes each comment based on keywords found in the review body (e.g., "Actionable comments posted", "Nitpick comments").
5. Assembles the final prompt string by populating the static template with the dynamic PR context and the structured `<review_comments>` block.

This LLM-free, deterministic process ensures consistency, speed, and predictability, providing a reliable foundation for subsequent AI-driven analysis.