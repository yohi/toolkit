# AI Agent Instruction Prompt Specification

## 1. Overview

This document specifies the structure and content of the AI Agent Instruction Prompt generated by the CodeRabbit Comment Fetcher. The prompt is designed to be fully compliant with [Claude 4's best practices](https://docs.claude.com/en/docs/build-with-claude/prompt-engineering/overview.md) for clarity, structure, and effectiveness.

The entire prompt is generated **mechanically** from the data fetched via the GitHub CLI. **No LLM is used in the prompt generation process itself.** The process is a deterministic, rule-based transformation of raw PR data into a structured format that an AI agent can easily parse and act upon.

## 2. Core Design Principles

- **Deterministic Generation**: The prompt is generated through a purely mechanical process (e.g., string manipulation, regex) without any LLM-based analysis or summarization. This ensures that the same input from the GitHub API always produces the exact same output.
- **Structured for Clarity**: The prompt uses a combination of Markdown and XML-style tags to clearly delineate different sections and types of information, making it easy for an AI agent to parse.
- **Role-Based Persona**: A static `<role>` tag is included at the beginning to provide the AI agent with a consistent persona as a senior software engineer, guiding its analysis and response style.
- **Action-Oriented**: The prompt's primary goal is to present raw, actionable feedback from CodeRabbit in a structured manner, enabling the AI agent to focus on analysis and solution generation.
- **Keyword-Based Analysis**: Utilizes predefined keyword dictionaries for mechanical classification and prioritization of issues.
- **Deterministic Processing**: Implements rule-based algorithms for priority assignment and timeline determination.

## 3. Prompt Structure

The generated prompt consists of the following sections in order:

### 3.1. Static Header

This section provides the AI agent with its persona and a general methodology for analysis. The content is static and included in every generated prompt.

- **`<role>`**: Defines the persona for the AI agent (e.g., senior software engineer specializing in code review, security, performance, and architecture).
- **`<principles>`**: Lists the core guiding principles for the agent's work (Quality, Security, Standards, Specificity, Impact-awareness).
- **`<analysis_steps>`**: Outlines a step-by-step approach: Issue identification â†’ Impact assessment â†’ Solution design â†’ Implementation plan â†’ Verification method.
- **`<core_principles>`**: Reinforces the fundamental principles for consistent analysis.
- **`<analysis_methodology>`**: Detailed methodology framework for systematic analysis.
- **`<priority_matrix>`**: Defines priority levels (Critical, High, Medium, Low) with specific criteria.
- **`<impact_scope>`**: Categorizes impact levels (System, Module, Function, Line).

### 3.2. Dynamic Context

This section provides the specific context of the pull request being analyzed. All information is dynamically populated from the GitHub CLI output.

- **`## Pull Request Context`**: Contains comprehensive metadata about the PR including:
  - PR URL, title, description, branch, author
  - File change statistics (files changed, lines added/deleted)
  - Technical context (repository type, key technologies, file extensions, build system)
- **`## CodeRabbit Review Summary`**: Provides a high-level, mechanically-counted summary:
  - Total comments categorized by type (Actionable, Nitpick, Outside Diff Range)
  - Statistical breakdown of comment distribution

### 3.3. Analysis Task Definition

This section instructs the AI agent on what to do with the provided data and what the expected output format is.

- **`# Analysis Task`**: A clear instruction to analyze the comments within the `<review_comments>` block.
- **`<execution_guidelines>`**: Detailed processing approach and output requirements including:
  - Step-by-step processing methodology
  - Quality assurance requirements
  - Success criteria for implementation
- **`<comment_metadata>`**: Comprehensive metadata about the comments including:
  - Comment type distribution and priority classification
  - Technology stack and complexity assessment
  - Risk evaluation and estimated resolution time
- **`<thinking_process>`**: Step-by-step analytical framework for processing each comment
- **`<error_handling>`**: Guidelines for handling edge cases and missing data
- **`<language_rules>`**: Specifications for multilingual output (Japanese/English hybrid)
- **`<output_format>`**: Detailed template structure for consistent response formatting

### 3.4. Structured Comments Block

This is the core of the prompt, containing the structured data of the CodeRabbit comments.

- **`<review_comments>`**: The root tag containing all individual review comments.
- **`<review_comment>`**: A container for a single piece of feedback from CodeRabbit.
  - **`type` attribute**: The category of the comment, mechanically determined (e.g., `Actionable`, `Nitpick`, `OutsideDiff`).
  - **`file` attribute**: The file path the comment pertains to.
  - **`lines` attribute**: The line number or range the comment pertains to.

  - **`<issue>` tag**: Contains the title or main point of the CodeRabbit comment.
  - **`<instructions>` tag**: Contains the detailed body of the CodeRabbit comment, including any instructions or explanations. For comments that originally included a "ðŸ¤– Prompt for AI Agents", that text is placed here.
  - **`<proposed_diff>` tag**: Contains the suggested code changes with structured old_code/new_code sections:
    - **`old_code:`**: Current problematic code
    - **`new_code:`**: Proposed solution code

### 3.5. Static Footer

- **`# Analysis Instructions`**: Contains comprehensive analysis framework including:
  - **`<deterministic_processing_framework>`**: Rule-based processing steps with keyword dictionaries
  - **`<verification_templates>`**: Specific verification procedures for different comment types
  - **Final processing instructions**: Guidelines for systematic comment analysis

## 4. Generation Process

The prompt is generated by the `coderabbit-fetcher` tool, which:
1. Fetches PR data (metadata and review comments) using `gh pr view --json ...`.
2. Parses the raw JSON response.
3. Iterates through the review comments, extracting the title, body, file path, line numbers, and suggested diff for each piece of feedback.
4. Categorizes each comment based on keywords found in the review body (e.g., "Actionable comments posted", "Nitpick comments").
5. Assembles the final prompt string by populating the static template with the dynamic PR context and the structured `<review_comments>` block.
6. Applies deterministic keyword classification using predefined dictionaries:
   - security_keywords: vulnerability, security, authentication, authorization, injection, XSS, CSRF, token, credential, encrypt
   - functionality_keywords: breaks, fails, error, exception, crash, timeout, install, command, PATH, export
   - quality_keywords: refactor, maintainability, readability, complexity, duplicate, cleanup, optimize
   - style_keywords: formatting, naming, documentation, comment, PHONY, alias, help
7. Generates structured metadata including priority assessment, impact scope, and resolution timelines.

This LLM-free, deterministic process ensures consistency, speed, and predictability, providing a reliable foundation for subsequent AI-driven analysis with built-in quality assurance and verification frameworks.
